# Задание 3. Создание векторного индекса базы знаний

Здесь мы создаём извлекаем векторные индексы из документов базы знаний с использованием моделей эмбеддингов семейства Qwen3-Embedding-**

## Структура файлов

### Python-скрипты

#### `pydantic_dto.py`
Определяет структуры данных для хранения чанков и эмбеддингов:
- **`TextChunkInfo`** — информация об одном чанке текста (диапазоны токенов и символов, сам текст)
- **`TextEmbeddingsInfo`** — эмбеддинги всех чанков одного документа + метаданные

#### `extract_embeddings_for_kb.py`
Скрипт для создания эмбеддингов из документов базы знаний.

Там реализована функция **`encode_documents(mdl, documents, chunk_size=500, overlap_size=50)`**, которая рзбивает документы на перекрывающиеся чанки и создаёт для них эмбеддинги.
  - `mdl` — модель SentenceTransformer
  - `documents` — словарь {Path: текст документа}
  - `chunk_size` — размер чанка в токенах (по умолчанию 500)
  - `overlap_size` — размер перекрытия между чанками в токенах (по умолчанию 50)
Возвращает: `List[TextEmbeddingsInfo]`

Параметры чанков:
- `DOC_CHUNK_SIZE = 500` токенов
- `DOC_OVERLAPPING_SIZE = 50` токенов

**Запуск:**
```bash
python extract_embeddings_for_kb.py
```
Создаёт файлы:
- `doc_embeddings_chunked-0.6B.pck` (пользуем модель `Qwen3-Embedding-0.6B`, считаем на GPU)
- `doc_embeddings_chunked-4B-8bit.pck` (пользуем модель `Qwen3-Embedding-0.6B`, считаем на GPU, но с 8-битной квантизацией, чтобы влезло в видеопамять на моей старенькой GTX 1080Ti) 
- `doc_embeddings_chunked-4B.pck` (пользуем модель `Qwen3-Embedding-0.6B`, считаем на GPU, считаем на CPU: примедленнее, но приемлемо, и без квантизации, т.е. с полноценным FP16)
- `questions_embeddings-0.6B.pck`
- `questions_embeddings-4B.pck`
- `questions_embeddings-4B-8bit.pck`

Время расчёта:
- `Qwen3-Embedding-0.6B` (GPU): 7.93 сек
- `Qwen3-Embedding-4B` (GPU, 8-bit): 75.35 сек (вполне приемлемо)
- `Qwen3-Embedding-4B` (CPU): 855.96 сек (очень долго, расчёт на CPU годится только для тестовых задач и оценки)

Лог запуска -- см. [`embedding_generation.log`](embedding_generation.log)

#### `create_index.py`
Скрипт для создания векторных индексов FAISS и ChromaDB из сохранённых эмбеддингов.

Открывает ранее сохранённые эмбеддинги, создаёт индексы ChromaDB с косинусной метрикой расстояния и полными метаданными чанков в папках:
- [`chroma/chroma-0.6B`](chroma/chroma-0.6B)
- [`chroma/chroma-4B`](chroma/chroma-4B)
- [`chroma/chroma-4B-8bit`](chroma/chroma-4B-8bit)

Проводит тестовый поиск по вопросам.

**Запуск:**
```bash
python create_index.py
```

Лог запуска -- см. [vector_index_generation.log](vector_index_generation.log)

- `4B` без квантизации: предсказуемо отрабатывает лучше всех (чанки, которые должны найтись, не только попадают в топ-5, но и находятся на первом месте).
- `4B-8bit` отрабатывает чуть хуже, но приемлемо (чанки, которые должны найтись, попадают в топ-5, но не всегда на 1-м месте);
- `0.6` работает так себе: иногда нужные чанки вообще не попадают в топ-5 (особенно хорошо видно по последнему вопросу: "Кто в игре собирался поступать в институт?")

### Файлы данных

#### YAML-файлы с вопросами

- **`questions.yaml`** — 5 вопросов для ручной проверки векторного поиска. На эти вопросы ответы **должны быть найдены** в базе знаний:
  - "Какой город невидим для взглядов чужаков?"
  - "Кому поклоняются умные ящерицы?"
  - "Кто работает доктором в Дождливых Холмах?"
  - "Какое в игре главное средство воздухоплавания?"
  - "Кто в игре собирался поступать в институт?"

- **`not_found_questions.yaml`** — 5 вопросов для проверки поведения на отсутствующую информацию. Ответов на эти вопросы в базе знаний **нет**, система должна корректно обработать их отсутствие:
  - "Что такое Arcanum?"
  - "Кто такой Андрей?"
  - "Кто убил Хринджила?"
  - "Что ты знаешь о вулканах?"
  - "Какой у нас суперпароль?"

#### Pickle-файлы с эмбеддингами

- **`doc_embeddings_chunked-{suffix}.pck`** — эмбеддинги всех чанков документов из базы знаний
- **`questions_embeddings-{suffix}.pck`** — эмбеддинги тестовых вопросов
- `{suffix}` может быть: `0.6B`, `4B`, `4B-8bit` (в зависимости от модели и квантизации)

#### Директории

- **`chroma/`** — хранилище векторных индексов ChromaDB с метаданными для каждого чанка

