#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ Ragas evaluation —Å –ª–æ–∫–∞–ª—å–Ω–æ–π Ollama-–º–æ–¥–µ–ª—å—é qwen3:8b.
–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
  - ollama —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –∑–∞–ø—É—â–µ–Ω (https://ollama.com)
  - –º–æ–¥–µ–ª—å qwen3:8b –∑–∞–≥—Ä—É–∂–µ–Ω–∞: `ollama pull qwen3:8b`
  - Python-–ø–∞–∫–µ—Ç—ã: ragas, langchain-ollama
  - sentence-transformers (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è —Å ragas)

–ü—Ä–∏–º–µ—Ä –∑–∞–ø—É—Å–∫–∞:
  ollama pull qwen3:8b
  python evaluate_rag_responses.py --input dataset.json --out results.json

"""
import argparse
import json
import logging
import sys
from ragas import evaluate
from ragas.dataset_schema import EvaluationDataset
from ragas.embeddings import LangchainEmbeddingsWrapper
from ragas.llms import LangchainLLMWrapper
from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall

# LangChain imports
try:
    from langchain_ollama import ChatOllama
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_core.callbacks import BaseCallbackHandler
    from langchain_core.outputs import LLMResult
    from sentence_transformers import SentenceTransformer
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    print("–¢—Ä–µ–±—É—é—Ç—Å—è –ø–∞–∫–µ—Ç—ã: pip install langchain-ollama langchain-huggingface")
    sys.exit(1)


class LLMLoggingCallback(BaseCallbackHandler):
    """Callback –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ LLM –∏ –æ—Ç–≤–µ—Ç–æ–≤"""
    
    def __init__(self):
        self.request_count = 0
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –Ω–∞—á–∞–ª–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ LLM"""
        self.request_count += 1
        print(f"\n{'='*80}")
        print(f"üîµ LLM REQUEST #{self.request_count}")
        print(f"{'='*80}")
        for i, prompt in enumerate(prompts, 1):
            print(f"\n--- –ü—Ä–æ–º–ø—Ç {i}/{len(prompts)} ---")
            print(prompt)
            print(f"--- –ö–æ–Ω–µ—Ü –ø—Ä–æ–º–ø—Ç–∞ {i} ---")
    
    def on_llm_end(self, response: LLMResult, **kwargs):
        """–í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM"""
        print(f"\n{'='*80}")
        print(f"üü¢ LLM RESPONSE #{self.request_count}")
        print(f"{'='*80}")
        for i, generation in enumerate(response.generations, 1):
            for j, gen in enumerate(generation, 1):
                print(f"\n--- –û—Ç–≤–µ—Ç {i}.{j} ---")
                print(gen.text)
                print(f"--- –ö–æ–Ω–µ—Ü –æ—Ç–≤–µ—Ç–∞ {i}.{j} ---")
        print(f"{'='*80}\n")


def load_dataset_json(path: str):
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è EvaluationDataset
    n = len(data.get("questions", []))
    examples = []
    for i in range(n):
        q = data["questions"][i]
        resp = data["answers"][i] if i < len(data.get("answers", [])) else ""
        ref = data["ground_truths"][i] if i < len(data.get("ground_truths", [])) else None
        contexts = data["contexts"][i] if i < len(data.get("contexts", [])) else None
        examples.append({"user_input": q, "response": resp, "reference": ref, "retrieved_contexts": contexts})
    return examples


def main():
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", "-i", required=True, help="Path to dataset.json")
    parser.add_argument("--out", "-o", default="ragas_results_ollama.json", help="Output path")
    parser.add_argument("--model", default="qwen3:8b", help="Ollama model name (default qwen3:8b)")
    parser.add_argument("--embedding_model", default="Qwen/Qwen3-Embedding-4B", 
                        help="HuggingFace embedding model (default: Qwen3-Embedding-4B)")
    parser.add_argument("--batch_size", type=int, default=4)
    args = parser.parse_args()

    samples = load_dataset_json(args.input)
    samples = [s for s in samples if s["user_input"] and s["response"]]
    if not samples:
        print("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –≤—Ö–æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ.")
        return

    eval_dataset = EvaluationDataset.from_list(samples)

    # –°–æ–∑–¥–∞—ë–º –ª–æ–∫–∞–ª—å–Ω—ã–µ embeddings (HuggingFace) –Ω–∞ CPU
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ embedding –º–æ–¥–µ–ª–∏ –Ω–∞ CPU: {args.embedding_model}...")
    
    # –î–ª—è Qwen3-Embedding –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ –∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —á—Ç–æ –∏ –≤ extract_embeddings_for_kb.py
    # HuggingFaceEmbeddings –ø—Ä–∏–Ω–∏–º–∞–µ—Ç model_name (—Å—Ç—Ä–æ–∫—É) –∏ model_kwargs
    if "Qwen3-Embedding" in args.embedding_model:
        langchain_embeddings = HuggingFaceEmbeddings(
            model_name=args.embedding_model,
            model_kwargs={"device": "cpu", "tokenizer_kwargs": {"padding_side": "left"}},
            encode_kwargs={"normalize_embeddings": True}
        )
    else:
        langchain_embeddings = HuggingFaceEmbeddings(
            model_name=args.embedding_model,
            model_kwargs={"device": "cpu"},
            encode_kwargs={"normalize_embeddings": True}
        )
    
    # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –¥–ª—è ragas (—Å –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ–º deprecation warning)
    import warnings
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=DeprecationWarning)
        ragas_embeddings = LangchainEmbeddingsWrapper(langchain_embeddings)

    # –°–æ–∑–¥–∞—ë–º ChatOllama –∏–∑ langchain-ollama (–Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è)
    print(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Ollama –º–æ–¥–µ–ª–∏: {args.model}...")
    
    # –°–æ–∑–¥–∞—ë–º callback –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤
    llm_callback = LLMLoggingCallback()
    
    # –í–∫–ª—é—á–∞–µ–º verbose –∏ –¥–æ–±–∞–≤–ª—è–µ–º callback –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    chat_ollama = ChatOllama(
        model=args.model, 
        temperature=0.0, 
        verbose=True,
        callbacks=[llm_callback]
    )
    llm_wrapper = LangchainLLMWrapper(chat_ollama)

    print("–ó–∞–ø—É—Å–∫–∞—é evaluate() —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ ‚Äî —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏...")
    print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: batch_size={args.batch_size} (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –æ—Ü–µ–Ω–∫–∏, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º—ã—Ö –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
    metrics = [
        faithfulness,         # –í–µ—Ä–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (–Ω–µ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π)
        answer_relevancy,     # –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –≤–æ–ø—Ä–æ—Å—É
        context_precision,    # –¢–æ—á–Ω–æ—Å—Ç—å –∏–∑–≤–ª–µ—á—ë–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context_recall        # –ü–æ–ª–Ω–æ—Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–ø–æ–∫—Ä—ã–≤–∞–µ—Ç –ª–∏ ground truth)
    ]
    
    print(f"\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ ({len(metrics)} –º–µ—Ç—Ä–∏–∫):")
    for i, metric in enumerate(metrics, 1):
        print(f"  {i}. {metric.name}: {metric.__doc__.split('.')[0] if metric.__doc__ else 'N/A'}")
    
    total_tasks = len(samples) * len(metrics)
    num_batches = (total_tasks + args.batch_size - 1) // args.batch_size
    print(f"\nüî¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á: {len(samples)} –ø—Ä–∏–º–µ—Ä–æ–≤ √ó {len(metrics)} –º–µ—Ç—Ä–∏–∫ = {total_tasks} –∑–∞–¥–∞—á")
    print(f"   –ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤ {num_batches} –±–∞—Ç—á–∞—Ö –ø–æ {args.batch_size} –∑–∞–¥–∞—á\n")
    
    result = evaluate(
        eval_dataset, 
        llm=llm_wrapper, 
        embeddings=ragas_embeddings,
        metrics=metrics,  # –Ø–≤–Ω–æ –ø–µ—Ä–µ–¥–∞—ë–º –º–µ—Ç—Ä–∏–∫–∏
        show_progress=True, 
        batch_size=args.batch_size
    )

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è JSON-—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    print(f"\nüìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏:")
    result_dict = result.to_pandas().to_dict('records')
    
    # –¢–∞–∫–∂–µ –≤—ã–≤–æ–¥–∏–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
    print(f"  –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫:")
    for metric_name in result.to_pandas().columns:
        if metric_name not in ['user_input', 'response', 'retrieved_contexts', 'reference']:
            mean_value = result.to_pandas()[metric_name].mean()
            print(f"    {metric_name}: {mean_value:.4f}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON
    with open(args.out, "w", encoding="utf-8") as f:
        json.dump(result_dict, f, ensure_ascii=False, indent=2)

    print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {args.out}")


if __name__ == "__main__":
    main()
