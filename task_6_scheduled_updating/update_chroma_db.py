import logging
import shutil
import sys
from pathlib import Path
from typing import List, Optional

import chromadb
from chromadb.config import Settings
from more_itertools import chunked
from sentence_transformers import SentenceTransformer

# –ò–º–ø–æ—Ä—Ç —Ñ—É–Ω–∫—Ü–∏–π –∏–∑ task_3_vector_index
sys.path.insert(0, str(Path(__file__).parent.parent))
from task_3_vector_index.extract_embeddings_for_kb import encode_documents
from task_6_scheduled_updating.file_hashing import calculate_hashes, compare_hashes

N_DOCS_PER_BATCH = 3


def update_embeddings(
    old_chroma_dir_path: Optional[Path],
    new_chroma_dir_path: Path,
    new_files: List[Path],
    modified_files: List[Path],
    deleted_files: List[Path],
    qwen3_suffix="4B",
) -> Path:
    """
    –ö–æ–ø–∏—Ä—É–µ—Ç —Å—Ç–∞—Ä—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é ChromaDB –≤ new_chroma_dir (–µ—Å–ª–∏ old_chroma_dir_path == None, —Ç–æ —Å–æ–∑–¥–∞—ë—Ç —Ç–∞–º –Ω–æ–≤—É—é –±–∞–∑—É).
    –ó–∞—Ç–µ–º —É–¥–∞–ª—è–µ—Ç –æ—Ç—Ç—É–¥–∞ modified_files –∏ deleted_files.
    –ó–∞—Ç–µ–º —Å—á–∏—Ç–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–æ new_files –∏ modified_files –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –∏—Ö –≤ –±–∞–∑—É.

    Args:
        old_chroma_dir_path: –ø—É—Ç—å –∫ —Å—Ç–∞—Ä–æ–π ChromaDB (–∏–ª–∏ None –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–π)
        new_chroma_dir_path: –ø—É—Ç—å –¥–ª—è –Ω–æ–≤–æ–π ChromaDB
        new_files: —Å–ø–∏—Å–æ–∫ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
        modified_files: —Å–ø–∏—Å–æ–∫ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        deleted_files: —Å–ø–∏—Å–æ–∫ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        qwen3_suffix: —Å—É—Ñ—Ñ–∏–∫—Å –º–æ–¥–µ–ª–∏ Qwen ("0.6B" –∏–ª–∏ "4B")

    Returns:
        –ø—É—Ç—å –∫ –Ω–æ–≤–æ–π ChromaDB
    """
    # 1. –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å –±–∞–∑—É
    if old_chroma_dir_path is not None and old_chroma_dir_path.exists() and old_chroma_dir_path.is_dir():
        # –ö–æ–ø–∏—Ä—É–µ–º —Å—Ç–∞—Ä—É—é –±–∞–∑—É
        if new_chroma_dir_path.exists() and new_chroma_dir_path.is_dir():
            shutil.rmtree(new_chroma_dir_path, ignore_errors=True)
        shutil.copytree(old_chroma_dir_path, new_chroma_dir_path)
        logging.info(f"‚úÖ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ –±–∞–∑–∞ –∏–∑ {old_chroma_dir_path} –≤ {new_chroma_dir_path}")
    else:
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –±–∞–∑—É (–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ–∑–¥–∞—Å—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞)
        logging.info(f"üÜï –°–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤–∞—è –±–∞–∑–∞ –≤ {new_chroma_dir_path}")

    # 2. –û—Ç–∫—Ä—ã—Ç—å ChromaDB
    chroma_client = chromadb.PersistentClient(
        path=str(new_chroma_dir_path), settings=Settings(anonymized_telemetry=False)
    )

    collection_name = "kb_embeddings"

    # –ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é
    try:
        collection = chroma_client.get_collection(name=collection_name)
    except:
        collection = chroma_client.create_collection(name=collection_name, metadata={"hnsw:space": "l2"})

    # 3. –£–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å–∏ –¥–ª—è modified_files –∏ deleted_files
    files_to_delete = deleted_files + modified_files
    if files_to_delete:
        logging.info(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–∏–µ {len(files_to_delete)} —Ñ–∞–π–ª–æ–≤ –∏–∑ –±–∞–∑—ã...")
        for file_path in files_to_delete:
            # –£–¥–∞–ª—è–µ–º –≤—Å–µ —á–∞–Ω–∫–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å —ç—Ç–∏–º —Ñ–∞–π–ª–æ–º
            try:
                collection.delete(where={"source_path": str(file_path)})
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {file_path}: {e}")

    # 4. –í—ã—á–∏—Å–ª–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è new_files –∏ modified_files
    files_to_add = new_files + modified_files
    if files_to_add:
        logging.info(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∏–µ {len(files_to_add)} —Ñ–∞–π–ª–æ–≤ –≤ –±–∞–∑—É (–±–∞—Ç—á–∞–º–∏ –ø–æ {N_DOCS_PER_BATCH})...")

        # –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        use_cpu = True  # –ú–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º
        model = SentenceTransformer(
            f"Qwen/Qwen3-Embedding-{qwen3_suffix}",
            device="cpu" if use_cpu else None,
            tokenizer_kwargs={"padding_side": "left"},
        )

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –±–∞—Ç—á–∞–º–∏
        chunk_idx = 0
        total_chunks_added = 0

        for batch_num, file_batch in enumerate(chunked(files_to_add, N_DOCS_PER_BATCH), start=1):
            logging.info(f"  üì¶ –ë–∞—Ç—á {batch_num}: –æ–±—Ä–∞–±–æ—Ç–∫–∞ {len(file_batch)} —Ñ–∞–π–ª–æ–≤...")

            # –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –±–∞—Ç—á–∞
            documents = {}
            for file_path in file_batch:
                if file_path.exists() and file_path.is_file():
                    with open(file_path, "r", encoding="utf-8") as f:
                        documents[file_path] = f.read()

            if not documents:
                logging.warning(f"  ‚ö†Ô∏è  –ë–∞—Ç—á {batch_num}: –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                continue

            # –í—ã—á–∏—Å–ª–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –±–∞—Ç—á–∞
            embeddings_list = encode_documents(model, documents)

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ ChromaDB
            batch_embeddings = []
            batch_metadatas = []
            batch_ids = []

            for doc_info in embeddings_list:
                for i, chunk_info in enumerate(doc_info.chunks):
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º .dict() –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                    metadata = chunk_info.dict()
                    metadata["source_path"] = str(doc_info.original_text_path)

                    batch_embeddings.append(doc_info.embeddings[i].tolist())
                    batch_metadatas.append(metadata)
                    batch_ids.append(f"chunk_{chunk_idx}")
                    chunk_idx += 1

            # –î–æ–±–∞–≤–∏—Ç—å –±–∞—Ç—á –≤ –±–∞–∑—É
            if batch_embeddings:
                collection.add(embeddings=batch_embeddings, metadatas=batch_metadatas, ids=batch_ids)
                total_chunks_added += len(batch_embeddings)
                logging.info(f"  ‚úÖ –ë–∞—Ç—á {batch_num}: –¥–æ–±–∞–≤–ª–µ–Ω–æ {len(batch_embeddings)} —á–∞–Ω–∫–æ–≤")

        if total_chunks_added > 0:
            logging.info(f"‚úÖ –í—Å–µ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ {total_chunks_added} —á–∞–Ω–∫–æ–≤ –∏–∑ {len(files_to_add)} —Ñ–∞–π–ª–æ–≤")

    logging.info(f"‚úÖ –ë–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞: {new_chroma_dir_path}")
    return new_chroma_dir_path


def update_kb_index(
    doc_dir_path: Path,
    new_chroma_dir_path: Path,
    metadata_db_path: Path = Path(__file__).parent / "metadata.db",
    qwen3_suffix: str = "4B",
):
    """
    –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:
    - j
    -  –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ –ø–æ—Ä—è–¥–∫—É .pck-—Ñ–∞–π–ª –≤ hashes_dir_path (—Å—á–∏—Ç–∞–µ—Ç –µ–≥–æ —Ö–µ—à–∞–º–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)
    - –°—á–∏—Ç–∞–µ–º —Ö–µ—à–∏ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ doc_dir_path (—Å –ø–æ–º–æ—â—å—é calculate_hashes)
    - –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ö–µ—à–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ `hashes_dir_path` / f"{yyyy}-{mm}-{dd}_{hh}-{mm}-{ss}.pck"
    - –î–µ–ª–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ö–µ—à–µ–π —Å –ø–æ–º–æ—â—å—é compare_hashes –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ ChromaDB —Å –ø–æ–º–æ—â—å—é update_embeddings

    """


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

    old_folder_path = Path(__file__).parent.parent / "task_2_sample_dataset/arcanum_articles/text_output_replaced"

    old_hashes = calculate_hashes(old_folder_path)
    update_embeddings(
        Path(__file__).parent.parent / "task_3_vector_index/chroma/chroma-4B",
        Path("new_chroma-4B"),
        new_files=list(old_hashes.keys()),
        modified_files=[],
        deleted_files=[],
    )
