import logging
import shutil
import sys
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Dict

import chromadb
from chromadb.config import Settings
from more_itertools import chunked
from sentence_transformers import SentenceTransformer
from sqlalchemy import create_engine, select
from sqlalchemy.orm import Session

# –ò–º–ø–æ—Ä—Ç —Ñ—É–Ω–∫—Ü–∏–π –∏–∑ task_3_vector_index
sys.path.insert(0, str(Path(__file__).parent.parent))
from task_3_vector_index.extract_embeddings_for_kb import encode_documents
from task_6_scheduled_updating.file_hashing import calculate_hashes, compare_hashes
from task_6_scheduled_updating.sqla_models import Base, VectorIndexVersion, DocHash

N_DOCS_PER_BATCH = 3


def update_embeddings(
    old_chroma_dir_path: Optional[Path],
    new_chroma_dir_path: Path,
    new_files: List[Path],
    modified_files: List[Path],
    deleted_files: List[Path],
    qwen3_suffix="4B",
) -> Path:
    """
    –ö–æ–ø–∏—Ä—É–µ—Ç —Å—Ç–∞—Ä—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é ChromaDB –≤ new_chroma_dir (–µ—Å–ª–∏ old_chroma_dir_path == None, —Ç–æ —Å–æ–∑–¥–∞—ë—Ç —Ç–∞–º –Ω–æ–≤—É—é –±–∞–∑—É).
    –ó–∞—Ç–µ–º —É–¥–∞–ª—è–µ—Ç –æ—Ç—Ç—É–¥–∞ modified_files –∏ deleted_files.
    –ó–∞—Ç–µ–º —Å—á–∏—Ç–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–æ new_files –∏ modified_files –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –∏—Ö –≤ –±–∞–∑—É.

    Args:
        old_chroma_dir_path: –ø—É—Ç—å –∫ —Å—Ç–∞—Ä–æ–π ChromaDB (–∏–ª–∏ None –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–π)
        new_chroma_dir_path: –ø—É—Ç—å –¥–ª—è –Ω–æ–≤–æ–π ChromaDB
        new_files: —Å–ø–∏—Å–æ–∫ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
        modified_files: —Å–ø–∏—Å–æ–∫ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        deleted_files: —Å–ø–∏—Å–æ–∫ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        qwen3_suffix: —Å—É—Ñ—Ñ–∏–∫—Å –º–æ–¥–µ–ª–∏ Qwen ("0.6B" –∏–ª–∏ "4B")

    Returns:
        –ø—É—Ç—å –∫ –Ω–æ–≤–æ–π ChromaDB
    """
    # 1. –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å –±–∞–∑—É
    if old_chroma_dir_path is not None and old_chroma_dir_path.exists() and old_chroma_dir_path.is_dir():
        # –ö–æ–ø–∏—Ä—É–µ–º —Å—Ç–∞—Ä—É—é –±–∞–∑—É
        if new_chroma_dir_path.exists() and new_chroma_dir_path.is_dir():
            shutil.rmtree(new_chroma_dir_path, ignore_errors=True)
        shutil.copytree(old_chroma_dir_path, new_chroma_dir_path)
        logging.info(f"‚úÖ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∞ –±–∞–∑–∞ –∏–∑ {old_chroma_dir_path} –≤ {new_chroma_dir_path}")
    else:
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –±–∞–∑—É (–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ–∑–¥–∞—Å—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞)
        logging.info(f"üÜï –°–æ–∑–¥–∞–µ—Ç—Å—è –Ω–æ–≤–∞—è –±–∞–∑–∞ –≤ {new_chroma_dir_path}")

    # 2. –û—Ç–∫—Ä—ã—Ç—å ChromaDB
    chroma_client = chromadb.PersistentClient(
        path=str(new_chroma_dir_path), settings=Settings(anonymized_telemetry=False)
    )

    collection_name = "kb_embeddings"

    # –ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é
    try:
        collection = chroma_client.get_collection(name=collection_name)
    except:
        collection = chroma_client.create_collection(name=collection_name, metadata={"hnsw:space": "l2"})

    # 3. –£–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å–∏ –¥–ª—è modified_files –∏ deleted_files
    files_to_delete = deleted_files + modified_files
    if files_to_delete:
        logging.info(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–∏–µ {len(files_to_delete)} —Ñ–∞–π–ª–æ–≤ –∏–∑ –±–∞–∑—ã...")
        for file_path in files_to_delete:
            # –£–¥–∞–ª—è–µ–º –≤—Å–µ —á–∞–Ω–∫–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å —ç—Ç–∏–º —Ñ–∞–π–ª–æ–º
            try:
                collection.delete(where={"source_path": str(file_path)})
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {file_path}: {e}")

    # 4. –í—ã—á–∏—Å–ª–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è new_files –∏ modified_files
    files_to_add = new_files + modified_files
    if files_to_add:
        logging.info(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∏–µ {len(files_to_add)} —Ñ–∞–π–ª–æ–≤ –≤ –±–∞–∑—É (–±–∞—Ç—á–∞–º–∏ –ø–æ {N_DOCS_PER_BATCH})...")

        # –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        use_cpu = True  # –ú–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º
        model = SentenceTransformer(
            f"Qwen/Qwen3-Embedding-{qwen3_suffix}",
            device="cpu" if use_cpu else None,
            tokenizer_kwargs={"padding_side": "left"},
        )

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –±–∞—Ç—á–∞–º–∏
        chunk_idx = 0
        total_chunks_added = 0
        total_files = len(files_to_add)

        for batch_num, file_batch in enumerate(chunked(files_to_add, N_DOCS_PER_BATCH), start=1):
            start_doc = (batch_num - 1) * N_DOCS_PER_BATCH + 1
            end_doc = min(batch_num * N_DOCS_PER_BATCH, total_files)
            logging.info(f"  üì¶ –ë–∞—Ç—á {batch_num}: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å {start_doc} –ø–æ {end_doc}...")

            # –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –±–∞—Ç—á–∞
            documents = {}
            for file_path in file_batch:
                if file_path.exists() and file_path.is_file():
                    with open(file_path, "r", encoding="utf-8") as f:
                        documents[file_path] = f.read()

            if not documents:
                logging.warning(f"  ‚ö†Ô∏è  –ë–∞—Ç—á {batch_num}: –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                continue

            # –í—ã—á–∏—Å–ª–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –±–∞—Ç—á–∞
            embeddings_list = encode_documents(model, documents)

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ ChromaDB
            batch_embeddings = []
            batch_metadatas = []
            batch_ids = []

            for doc_info in embeddings_list:
                for i, chunk_info in enumerate(doc_info.chunks):
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º .dict() –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                    metadata = chunk_info.dict()
                    metadata["source_path"] = str(doc_info.original_text_path)

                    batch_embeddings.append(doc_info.embeddings[i].tolist())
                    batch_metadatas.append(metadata)
                    batch_ids.append(f"chunk_{chunk_idx}")
                    chunk_idx += 1

            # –î–æ–±–∞–≤–∏—Ç—å –±–∞—Ç—á –≤ –±–∞–∑—É
            if batch_embeddings:
                collection.add(embeddings=batch_embeddings, metadatas=batch_metadatas, ids=batch_ids)
                total_chunks_added += len(batch_embeddings)
                logging.info(f"  ‚úÖ –ë–∞—Ç—á {batch_num}: –¥–æ–±–∞–≤–ª–µ–Ω–æ {len(batch_embeddings)} —á–∞–Ω–∫–æ–≤")

        if total_chunks_added > 0:
            logging.info(f"‚úÖ –í—Å–µ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ {total_chunks_added} —á–∞–Ω–∫–æ–≤ –∏–∑ {len(files_to_add)} —Ñ–∞–π–ª–æ–≤")

    logging.info(f"‚úÖ –ë–∞–∑–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞: {new_chroma_dir_path}")
    return new_chroma_dir_path


def update_kb_index(
    doc_dir_path: Path,
    new_chroma_dir_path: Path,
    metadata_db_path: Path = Path(__file__).parent / "metadata.db",
    qwen3_suffix: str = "4B",
) -> Path:
    """
    –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:
    - –æ—Ç–∫—Ä—ã–≤–∞–µ–º SQLite-–ë–î –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö;
    - –∏—â–µ–º —Ç–∞–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –≤–µ—Ä—Å–∏—é –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å) -- —Ç.–µ. –ø—Ä–µ–¥—ã–¥—É—â—É—é –≤–µ—Ä—Å–∏—é —Ö–µ—à–µ–π;
    - —Å—á–∏—Ç–∞–µ–º —Ö–µ—à–∏ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ doc_dir_path (—Å –ø–æ–º–æ—â—å—é calculate_hashes) -- —Ç.–µ. –∞–∫—Ç—É–∞–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é —Ö–µ—à–µ–π;
    - –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é —Ö–µ—à–µ–π —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π (—Å –ø–æ–º–æ—â—å—é compare_hashes)
    - –æ–±–Ω–æ–≤–ª—è–µ–º ChromaDB —Å –ø–æ–º–æ—â—å—é update_embeddings (–Ω–æ–≤—É—é –±–∞–∑—É —Ä–∞–∑–º–µ—â–∞–µ–º –≤ new_chroma_dir_path)
    - –≤ —Å–ª—É—á–∞–µ —É—Å–ø–µ—Ö–∞ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –ë–î –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–æ–≤–æ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–º –∏–Ω–¥–µ–∫—Å–µ (–ø—É—Ç—å –∫ Chroma-–±–∞–∑–µ –∏ –Ω–∞–±–æ—Ä —Ö–µ—à–µ–π)

    Returns:
        –ø—É—Ç—å –∫ –Ω–æ–≤–æ–π ChromaDB
    """
    logging.info("=== –ù–∞—á–∞–ª–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ ===")

    # 1. –û—Ç–∫—Ä—ã—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å –ë–î –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    engine = create_engine(f"sqlite:///{metadata_db_path}", echo=False)
    Base.metadata.create_all(engine)
    logging.info(f"‚úÖ –ë–î –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {metadata_db_path}")

    # 2. –ù–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω—é—é –≤–µ—Ä—Å–∏—é –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
    old_chroma_path: Optional[Path] = None
    old_hashes: Dict[Path, str] = {}

    with Session(engine) as session:
        # –ó–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤–µ—Ä—Å–∏–∏ –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è
        stmt = select(VectorIndexVersion).order_by(VectorIndexVersion.created_at.desc()).limit(1)
        last_version = session.scalars(stmt).first()

        if last_version:
            old_chroma_path = Path(last_version.path)
            logging.info(f"üìÇ –ù–∞–π–¥–µ–Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–∞—è –≤–µ—Ä—Å–∏—è –∏–Ω–¥–µ–∫—Å–∞: {old_chroma_path}")
            logging.info(f"   –°–æ–∑–¥–∞–Ω–∞: {last_version.created_at}")
            logging.info(f"   –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(last_version.doc_hashes)}")

            # –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–∞—Ä—ã–µ —Ö–µ—à–∏
            for doc_hash in last_version.doc_hashes:
                old_hashes[Path(doc_hash.path)] = doc_hash.hash
        else:
            logging.info("üÜï –ü—Ä–µ–¥—ã–¥—É—â–∏—Ö –≤–µ—Ä—Å–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, —Å–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å —Å –Ω—É–ª—è")

    # 3. –í—ã—á–∏—Å–ª–∏—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ö–µ—à–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    logging.info(f"üîç –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ö–µ—à–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ {doc_dir_path}...")
    new_hashes = calculate_hashes(doc_dir_path)
    logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(new_hashes)}")

    # 4. –°—Ä–∞–≤–Ω–∏—Ç—å —Ö–µ—à–∏
    new_files, modified_files, deleted_files = compare_hashes(old_hashes, new_hashes)
    logging.info(f"üìä –ò–∑–º–µ–Ω–µ–Ω–∏—è:")
    logging.info(f"   –ù–æ–≤—ã–µ —Ñ–∞–π–ª—ã: {len(new_files)}")
    logging.info(f"   –ò–∑–º–µ–Ω—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {len(modified_files)}")
    logging.info(f"   –£–¥–∞–ª—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {len(deleted_files)}")

    # 5. –û–±–Ω–æ–≤–∏—Ç—å ChromaDB
    logging.info(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ ChromaDB...")
    new_chroma_path = update_embeddings(
        old_chroma_dir_path=old_chroma_path,
        new_chroma_dir_path=new_chroma_dir_path,
        new_files=new_files,
        modified_files=modified_files,
        deleted_files=deleted_files,
        qwen3_suffix=qwen3_suffix,
    )

    # 6. –ó–∞–ø–∏—Å–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ –≤ –ë–î
    logging.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏...")
    with Session(engine) as session:
        # –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é –∏–Ω–¥–µ–∫—Å–∞
        new_version = VectorIndexVersion(path=str(new_chroma_dir_path.resolve()), created_at=datetime.utcnow())

        # –î–æ–±–∞–≤–∏—Ç—å —Ö–µ—à–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        for file_path, file_hash in new_hashes.items():
            doc_hash = DocHash(path=str(file_path.resolve()), hash=file_hash)
            new_version.doc_hashes.append(doc_hash)

        session.add(new_version)
        session.commit()

        logging.info(f"‚úÖ –í–µ—Ä—Å–∏—è –∏–Ω–¥–µ–∫—Å–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ (ID: {new_version.id})")
        logging.info(f"   –ü—É—Ç—å: {new_version.path}")
        logging.info(f"   –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(new_version.doc_hashes)}")

    logging.info("=== –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–æ ===")
    return new_chroma_path


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

    old_doc_folder_path = Path(__file__).parent.parent / "task_2_sample_dataset/arcanum_articles/text_output_replaced"

    # –°–æ–∑–¥–∞—ë–º –ø—É—Ç—å —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π: chroma_versions/4B/YYYY-MM-DD_hh-mm-ss
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    new_chroma_path = Path(__file__).parent / "chroma_versions" / "4B" / timestamp

    update_kb_index(old_doc_folder_path, new_chroma_path)

    # old_hashes = calculate_hashes(old_folder_path)
    # update_embeddings(
    #     Path(__file__).parent.parent / "task_3_vector_index/chroma/chroma-4B",
    #     Path("new_chroma-4B"),
    #     new_files=list(old_hashes.keys()),
    #     modified_files=[],
    #     deleted_files=[],
    # )
